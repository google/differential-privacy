name: Maven Tests

on: [push, pull_request, workflow_dispatch]

jobs:
  pipelinedp4j-tests:
    name: PipelineDP4J Maven Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v3
      - name: Cache Maven dependencies
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('examples/pipelinedp4j/pom.xml', 'examples/pipelinedp4j/**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-
      - name: Set up JDK 11
        uses: actions/setup-java@v3
        with:
          java-version: '11'
          distribution: 'temurin'
      - name: Install Maven
        run: sudo apt-get install -y maven
      - name: Create dummy input file for examples
        working-directory: examples/pipelinedp4j
        run: |
          cat << EOF > input.csv
          4505,573364,5,2004-13-29
          4501,2532865,4,2005-11-06
          4501,573364,2,2005-02-25
          4500,2532865,2,2004-12-12
          4505,1265574,4,2003-05-05
          4505,2532865,1,2004-12-12
          EOF
      - name: Install common package for examples
        working-directory: examples/pipelinedp4j
        run: mvn install
      - name: Run Beam Example
        working-directory: examples/pipelinedp4j/beam
        run: mvn compile exec:java -Dexec.mainClass=com.google.privacy.differentialprivacy.pipelinedp4j.examples.BeamExample -Dexec.args="--inputFilePath=$(pwd)/../input.csv --outputFilePath=output.txt"
      - name: Run Spark Example
        working-directory: examples/pipelinedp4j/spark
        run: mvn compile exec:java -Dexec.mainClass=com.google.privacy.differentialprivacy.pipelinedp4j.examples.SparkExample -Dexec.args="--inputFilePath=$(pwd)/../input.csv --outputFolder=output"
      - name: Run Spark DataFrame Example
        working-directory: examples/pipelinedp4j/spark
        run: mvn compile exec:java -Dexec.mainClass=com.google.privacy.differentialprivacy.pipelinedp4j.examples.SparkDataFrameExample -Dexec.args="--inputFilePath=$(pwd)/../input.csv --outputFolder=output"
      - name: Build Beam with Flink Runner
        working-directory: examples/pipelinedp4j/beam
        run: mvn package -Pflink-runner
      - name: Run Beam Example with Flink Runner
        working-directory: examples/pipelinedp4j/beam
        run: java -jar target/beam-1.0-SNAPSHOT.jar --runner=FlinkRunner --flinkMaster="[local]" --reIterableGroupByKeyResult=true --inputFilePath="../input.csv" --outputFilePath="output_flink.txt"
